{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5437be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables and create client\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "model = \"claude-3-5-haiku-latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b0d8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e788701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "Generate a evaluation dataset for a prompt evaluation. The dataset will be used to evaluate prompts\n",
    "that generate Python, JSON, or Regex specifically for AWS-related tasks. Generate an array of JSON objects,\n",
    "each representing task that requires Python, JSON, or a Regex to complete.\n",
    "\n",
    "Example output:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"task\": \"Description of task\",\n",
    "    },\n",
    "    ...additional\n",
    "]\n",
    "```\n",
    "\n",
    "* Focus on tasks that can be solved by writing a single Python function, a single JSON object, or a regular expression.\n",
    "* Focus on tasks that do not require writing much code\n",
    "\n",
    "Please generate 3 objects.\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "\n",
    "    answer = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75596f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset and store it on a json file\n",
    "dataset = generate_dataset()\n",
    "\n",
    "with open(\"dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b329b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(test_case):\n",
    "    \"\"\"Merges the prompt and test case input, then returns the result\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Please solve the following task:\n",
    "\n",
    "    {test_case[\"task\"]}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    add_user_message(messages, prompt)\n",
    "\n",
    "    output = chat(messages)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0628733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_by_model(test_case, output):\n",
    "    eval_prompt = f\"\"\"\n",
    "    You are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution.\n",
    "\n",
    "    Original Task:\n",
    "    <task>\n",
    "    {test_case[\"task\"]}\n",
    "    </task>\n",
    "\n",
    "    Solution to Evaluate:\n",
    "    <solution>\n",
    "    {output}\n",
    "    </solution>\n",
    "\n",
    "    Output Format\n",
    "    Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "    - \"strengths\": An array of 1-3 key strengths\n",
    "    - \"weaknesses\": An array of 1-3 key areas for improvement\n",
    "    - \"reasoning\": A concise explanation of your overall assessment\n",
    "    - \"score\": A number between 1-10\n",
    "\n",
    "    Respond with JSON. Keep your response concise and direct.\n",
    "    Example response shape:\n",
    "    {{\n",
    "        \"strengths\": string[],\n",
    "        \"weaknesses\": string[],\n",
    "        \"reasoning\": string,\n",
    "        \"score\": number\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    add_user_message(messages, eval_prompt)\n",
    "\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "\n",
    "    eval_text = chat(messages, stop_sequences=[\"```\"])\n",
    "\n",
    "    return json.loads(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e250dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_case(test_case):\n",
    "    \"\"\"Calls run_prompt, then grades the result\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "\n",
    "    # TODO: Grading \n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "    return {\n",
    "        \"output\": output,\n",
    "        \"test_case\": test_case,\n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17a8d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset and calls run_test_case with each case\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20a5639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run eval pipeline\n",
    "\n",
    "with open(\"dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f2e7dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"output\": \"Here's a comprehensive solution to convert AWS EC2 instance states to human-readable statuses:\\n\\n```python\\ndef convert_ec2_instance_state(state):\\n    \\\"\\\"\\\"\\n    Convert AWS EC2 instance state to a human-readable status.\\n    \\n    Args:\\n        state (str): The current state of the EC2 instance\\n    \\n    Returns:\\n        str: A human-readable description of the instance state\\n    \\\"\\\"\\\"\\n    # Dictionary mapping AWS EC2 instance states to readable descriptions\\n    state_mapping = {\\n        # Pending states\\n        'pending': 'Launching - Instance is being prepared',\\n        \\n        # Running states\\n        'running': 'Active - Instance is running normally',\\n        \\n        # Stopping/Stopped states\\n        'stopping': 'Shutting Down - Instance is in the process of stopping',\\n        'stopped': 'Stopped - Instance is shut down and not running',\\n        \\n        # Terminated states\\n        'terminating': 'Terminating - Instance is being permanently deleted',\\n        'terminated': 'Terminated - Instance has been permanently deleted',\\n        \\n        # Error or unusual states\\n        'shutting-down': 'Shutting Down - Instance is in the process of termination',\\n        'error': 'Error - Instance is in an error state',\\n        \\n        # Additional potential states\\n        'hibernating': 'Hibernating - Instance is being hibernated',\\n        'hibernated': 'Hibernated - Instance is in a hibernated state'\\n    }\\n    \\n    # Convert input state to lowercase to handle case variations\\n    state_lower = state.lower()\\n    \\n    # Return the human-readable status, with a default fallback\\n    return state_mapping.get(state_lower, f'Unknown State: {state}')\\n\\n\\n# Example usage and testing\\ndef main():\\n    # Test various EC2 instance states\\n    test_states = [\\n        'running', \\n        'stopped', \\n        'pending', \\n        'terminated', \\n        'stopping', \\n        'RUNNING',  # Test case insensitivity\\n        'unknown'   # Test unknown state\\n    ]\\n    \\n    print(\\\"EC2 Instance State Conversion Examples:\\\")\\n    for state in test_states:\\n        readable_status = convert_ec2_instance_state(state)\\n        print(f\\\"State '{state}': {readable_status}\\\")\\n\\n\\n# Run the example\\nif __name__ == \\\"__main__\\\":\\n    main()\\n```\\n\\nThis solution offers several key features:\\n\\n1. **Comprehensive State Mapping**: \\n   - Covers all major AWS EC2 instance states\\n   - Provides human-readable descriptions\\n   - Handles case-insensitive inputs\\n\\n2. **Flexible Error Handling**:\\n   - Returns a descriptive message for unknown states\\n   - Prevents errors with unexpected inputs\\n\\n3. **Easy Extensibility**:\\n   - Simple dictionary-based mapping can be easily updated\\n   - Can add new states or modify descriptions as needed\\n\\n4. **Example Usage**:\\n   - Includes a `main()` function demonstrating how to use the conversion function\\n   - Provides test cases for different scenarios\\n\\nExample Output:\\n```\\nEC2 Instance State Conversion Examples:\\nState 'running': Active - Instance is running normally\\nState 'stopped': Stopped - Instance is shut down and not running\\nState 'pending': Launching - Instance is being prepared\\nState 'terminated': Terminated - Instance has been permanently deleted\\nState 'stopping': Shutting Down - Instance is in the process of stopping\\nState 'RUNNING': Active - Instance is running normally\\nState 'unknown': Unknown State: unknown\\n```\\n\\n**Potential Enhancements**:\\n- Add logging for tracking state conversions\\n- Integrate with AWS SDK for real-time state checking\\n- Create more detailed state descriptions\\n\\n**Usage Tips**:\\n- Use this function when you need to display EC2 instance states to users\\n- Can be integrated into monitoring, reporting, or management scripts\\n- Helps improve readability of technical information\\n\\nThe function provides a clean, simple way to convert technical AWS instance states into more understandable language.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Create a Python function to convert an AWS EC2 instance state to a human-readable status\"\n",
      "    },\n",
      "    \"score\": 10\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Here's a comprehensive JSON schema to validate an AWS CloudFormation template parameter configuration:\\n\\n```json\\n{\\n    \\\"$schema\\\": \\\"http://json-schema.org/draft-07/schema#\\\",\\n    \\\"type\\\": \\\"object\\\",\\n    \\\"properties\\\": {\\n        \\\"Parameters\\\": {\\n            \\\"type\\\": \\\"object\\\",\\n            \\\"additionalProperties\\\": {\\n                \\\"type\\\": \\\"object\\\",\\n                \\\"properties\\\": {\\n                    \\\"Type\\\": {\\n                        \\\"type\\\": \\\"string\\\",\\n                        \\\"enum\\\": [\\n                            \\\"String\\\",\\n                            \\\"Number\\\", \\n                            \\\"List<Number>\\\",\\n                            \\\"CommaDelimitedList\\\",\\n                            \\\"AWS::EC2::Image::Id\\\",\\n                            \\\"AWS::EC2::KeyPair::KeyName\\\",\\n                            \\\"AWS::EC2::Subnet::Id\\\",\\n                            \\\"AWS::EC2::VPC::Id\\\",\\n                            \\\"AWS::Route53::HostedZone::Id\\\"\\n                        ]\\n                    },\\n                    \\\"Description\\\": {\\n                        \\\"type\\\": \\\"string\\\",\\n                        \\\"maxLength\\\": 4000\\n                    },\\n                    \\\"Default\\\": {\\n                        \\\"oneOf\\\": [\\n                            {\\\"type\\\": \\\"string\\\"},\\n                            {\\\"type\\\": \\\"number\\\"}\\n                        ]\\n                    },\\n                    \\\"AllowedValues\\\": {\\n                        \\\"type\\\": \\\"array\\\"\\n                    },\\n                    \\\"AllowedPattern\\\": {\\n                        \\\"type\\\": \\\"string\\\"\\n                    },\\n                    \\\"MinLength\\\": {\\n                        \\\"type\\\": \\\"integer\\\",\\n                        \\\"minimum\\\": 0\\n                    },\\n                    \\\"MaxLength\\\": {\\n                        \\\"type\\\": \\\"integer\\\",\\n                        \\\"minimum\\\": 0\\n                    },\\n                    \\\"MinValue\\\": {\\n                        \\\"type\\\": \\\"number\\\"\\n                    },\\n                    \\\"MaxValue\\\": {\\n                        \\\"type\\\": \\\"number\\\"\\n                    },\\n                    \\\"ConstraintDescription\\\": {\\n                        \\\"type\\\": \\\"string\\\",\\n                        \\\"maxLength\\\": 4000\\n                    },\\n                    \\\"NoEcho\\\": {\\n                        \\\"type\\\": \\\"boolean\\\"\\n                    }\\n                },\\n                \\\"required\\\": [\\\"Type\\\"],\\n                \\\"additionalProperties\\\": false\\n            }\\n        }\\n    },\\n    \\\"additionalProperties\\\": true\\n}\\n```\\n\\nThis JSON schema provides validation for AWS CloudFormation template parameters with the following features:\\n\\n1. Supports multiple parameter types:\\n   - Primitive types: String, Number\\n   - List types: List<Number>, CommaDelimitedList\\n   - AWS-specific resource types like EC2 Image ID, Key Pair, Subnet, VPC, etc.\\n\\n2. Validation constraints:\\n   - `Description`: Optional text description, max 4000 characters\\n   - `Default`: Optional default value\\n   - `AllowedValues`: Optional array of allowed values\\n   - `AllowedPattern`: Optional regex pattern for string validation\\n   - `MinLength` and `MaxLength`: String/list length constraints\\n   - `MinValue` and `MaxValue`: Numeric value constraints\\n   - `ConstraintDescription`: Optional custom error message\\n   - `NoEcho`: Boolean flag for sensitive parameters\\n\\n3. Flexible structure allowing additional CloudFormation template properties\\n\\nExample usage:\\n\\n```json\\n{\\n    \\\"Parameters\\\": {\\n        \\\"InstanceType\\\": {\\n            \\\"Type\\\": \\\"String\\\",\\n            \\\"Description\\\": \\\"EC2 instance type\\\",\\n            \\\"Default\\\": \\\"t2.micro\\\",\\n            \\\"AllowedValues\\\": [\\\"t2.micro\\\", \\\"t2.small\\\", \\\"t2.medium\\\"],\\n            \\\"ConstraintDescription\\\": \\\"Must be a valid EC2 instance type\\\"\\n        },\\n        \\\"DatabasePassword\\\": {\\n            \\\"Type\\\": \\\"String\\\",\\n            \\\"NoEcho\\\": true,\\n            \\\"MinLength\\\": 8,\\n            \\\"MaxLength\\\": 41,\\n            \\\"AllowedPattern\\\": \\\"^[a-zA-Z0-9]+$\\\"\\n        }\\n    }\\n}\\n```\\n\\nThis schema ensures robust validation of CloudFormation template parameters while maintaining flexibility for different use cases.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a JSON schema to validate an AWS CloudFormation template parameter configuration\"\n",
      "    },\n",
      "    \"score\": 10\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Here's a comprehensive solution for extracting AWS ARN using regex:\\n\\n```python\\nimport re\\n\\n# Comprehensive AWS ARN regex pattern\\nARN_PATTERN = r'arn:aws:([a-zA-Z0-9-]+):([a-z0-9-]+):(\\\\d{12})?:([a-zA-Z0-9-_/]+)'\\n\\ndef extract_arn(text):\\n    \\\"\\\"\\\"\\n    Extract AWS ARN from a given text\\n    \\n    Args:\\n        text (str): Input text containing potential AWS ARN\\n    \\n    Returns:\\n        dict or None: Parsed ARN details or None if no ARN found\\n    \\\"\\\"\\\"\\n    match = re.search(ARN_PATTERN, text)\\n    \\n    if match:\\n        return {\\n            'full_arn': match.group(0),\\n            'service': match.group(1),\\n            'region': match.group(2),\\n            'account_id': match.group(3) or None,\\n            'resource': match.group(4)\\n        }\\n    \\n    return None\\n\\n# Example usage and test cases\\ndef test_arn_extraction():\\n    test_cases = [\\n        # Various valid ARNs\\n        'arn:aws:ec2:us-west-2:123456789012:instance/i-1234567890abcdef0',\\n        'arn:aws:s3:::my-bucket',\\n        'arn:aws:iam::123456789012:user/username',\\n        'arn:aws:lambda:us-east-1:123456789012:function:my-function',\\n        \\n        # Invalid or partial ARNs\\n        'not an arn',\\n        'partial arn:aws:ec2'\\n    ]\\n    \\n    for case in test_cases:\\n        result = extract_arn(case)\\n        print(f\\\"Input: {case}\\\")\\n        print(f\\\"Result: {result}\\\\n\\\")\\n\\n# Run test cases\\ntest_arn_extraction()\\n```\\n\\nThis solution provides:\\n\\n1. A robust regex pattern that captures:\\n   - AWS service\\n   - Region\\n   - Optional account ID\\n   - Resource details\\n\\n2. An `extract_arn()` function that:\\n   - Searches for ARN in text\\n   - Returns parsed ARN details as a dictionary\\n   - Returns `None` if no ARN found\\n\\n3. Test cases covering various ARN formats\\n\\nKey regex components:\\n- `arn:aws:` - Fixed prefix\\n- `([a-zA-Z0-9-]+)` - Service name\\n- `([a-z0-9-]+)` - Region\\n- `(\\\\d{12})?` - Optional 12-digit account ID\\n- `([a-zA-Z0-9-_/]+)` - Resource identifier\\n\\nExample output:\\n```\\nInput: arn:aws:ec2:us-west-2:123456789012:instance/i-1234567890abcdef0\\nResult: {\\n    'full_arn': 'arn:aws:ec2:us-west-2:123456789012:instance/i-1234567890abcdef0', \\n    'service': 'ec2', \\n    'region': 'us-west-2', \\n    'account_id': '123456789012', \\n    'resource': 'instance/i-1234567890abcdef0'\\n}\\n```\\n\\nAdvantages:\\n- Flexible parsing\\n- Handles various AWS ARN formats\\n- Provides structured output\\n- Easy to extend or modify\\n\\nPotential improvements:\\n- Add more specific validation for each service\\n- Handle more complex ARN variations\\n- Implement stricter regex for specific use cases\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Develop a regex to extract AWS resource ARN (Amazon Resource Name) from a string\"\n",
      "    },\n",
      "    \"score\": 10\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Here's a comprehensive solution to calculate the monthly cost estimate for AWS S3 storage tiers:\\n\\n```python\\ndef calculate_s3_storage_cost(storage_tier, total_storage_gb, data_transfer_gb=0, request_type='standard'):\\n    \\\"\\\"\\\"\\n    Calculate monthly cost estimate for AWS S3 storage tiers.\\n    \\n    Args:\\n        storage_tier (str): Type of S3 storage tier\\n        total_storage_gb (float): Total storage size in GB\\n        data_transfer_gb (float, optional): Data transfer amount in GB. Defaults to 0.\\n        request_type (str, optional): Type of requests. Defaults to 'standard'.\\n    \\n    Returns:\\n        dict: Detailed cost breakdown for the specified S3 storage tier\\n    \\\"\\\"\\\"\\n    # AWS S3 pricing (as of 2023, US East region, subject to change)\\n    pricing = {\\n        'standard': {\\n            'storage_price_per_gb': 0.023,\\n            'data_transfer_out_per_gb': 0.09,\\n            'get_request_price': 0.0000004,\\n            'put_request_price': 0.0000005\\n        },\\n        'intelligent_tiering': {\\n            'storage_price_per_gb': 0.0125,\\n            'data_transfer_out_per_gb': 0.09,\\n            'monitoring_fee': 0.0025,\\n            'get_request_price': 0.0000004,\\n            'put_request_price': 0.0000005\\n        },\\n        'glacier_flexible_retrieval': {\\n            'storage_price_per_gb': 0.004,\\n            'data_transfer_out_per_gb': 0.09,\\n            'retrieval_price_per_gb': 0.03,\\n            'get_request_price': 0.0000004,\\n            'put_request_price': 0.0000005\\n        },\\n        'glacier_deep_archive': {\\n            'storage_price_per_gb': 0.00099,\\n            'data_transfer_out_per_gb': 0.09,\\n            'retrieval_price_per_gb': 0.02,\\n            'get_request_price': 0.0000004,\\n            'put_request_price': 0.0000005\\n        }\\n    }\\n    \\n    # Validate input storage tier\\n    if storage_tier.lower() not in pricing:\\n        raise ValueError(f\\\"Invalid storage tier. Choose from {list(pricing.keys())}\\\")\\n    \\n    # Get pricing for specific tier\\n    tier_pricing = pricing[storage_tier.lower()]\\n    \\n    # Calculate storage cost\\n    storage_cost = total_storage_gb * tier_pricing['storage_price_per_gb']\\n    \\n    # Calculate data transfer cost\\n    data_transfer_cost = data_transfer_gb * tier_pricing['data_transfer_out_per_gb']\\n    \\n    # Calculate request costs (assuming 10,000 requests per month)\\n    get_request_cost = 10000 * tier_pricing['get_request_price']\\n    put_request_cost = 10000 * tier_pricing['put_request_price']\\n    \\n    # Additional tier-specific calculations\\n    additional_costs = 0\\n    if storage_tier.lower() == 'intelligent_tiering':\\n        additional_costs += tier_pricing['monitoring_fee'] * total_storage_gb\\n    elif storage_tier.lower() in ['glacier_flexible_retrieval', 'glacier_deep_archive']:\\n        additional_costs += tier_pricing.get('retrieval_price_per_gb', 0) * total_storage_gb\\n    \\n    # Total monthly cost\\n    total_cost = (\\n        storage_cost + \\n        data_transfer_cost + \\n        get_request_cost + \\n        put_request_cost + \\n        additional_costs\\n    )\\n    \\n    return {\\n        'storage_tier': storage_tier,\\n        'total_storage_gb': total_storage_gb,\\n        'storage_cost': round(storage_cost, 2),\\n        'data_transfer_cost': round(data\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Create a Python function to calculate monthly cost estimate for a given AWS S3 storage tier\"\n",
      "    },\n",
      "    \"score\": 10\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Here's a JSON IAM policy that provides read-only access to an S3 bucket:\\n\\n```json\\n{\\n    \\\"Version\\\": \\\"2012-10-17\\\",\\n    \\\"Statement\\\": [\\n        {\\n            \\\"Effect\\\": \\\"Allow\\\",\\n            \\\"Action\\\": [\\n                \\\"s3:GetObject\\\",\\n                \\\"s3:ListBucket\\\",\\n                \\\"s3:GetBucketLocation\\\"\\n            ],\\n            \\\"Resource\\\": [\\n                \\\"arn:aws:s3:::your-bucket-name\\\",\\n                \\\"arn:aws:s3:::your-bucket-name/*\\\"\\n            ]\\n        }\\n    ]\\n}\\n```\\n\\nKey points about this policy:\\n\\n- `\\\"s3:GetObject\\\"` allows reading objects\\n- `\\\"s3:ListBucket\\\"` allows listing bucket contents\\n- `\\\"s3:GetBucketLocation\\\"` allows retrieving bucket region\\n- Replace `your-bucket-name` with the actual S3 bucket name\\n- The policy uses two resource ARNs: one for the bucket itself and one for its contents\\n- `\\\"Effect\\\": \\\"Allow\\\"` grants the specified permissions\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a JSON object representing IAM policy for read-only access to an S3 bucket\"\n",
      "    },\n",
      "    \"score\": 10\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"I'll help you design a regex to validate AWS Lambda function name constraints. Here's a comprehensive solution:\\n\\n```python\\nimport re\\n\\ndef validate_lambda_function_name(function_name):\\n    \\\"\\\"\\\"\\n    Validates an AWS Lambda function name according to AWS constraints:\\n    - Length: 1-64 characters\\n    - Allowed characters: Alphanumeric, hyphens, underscores\\n    - Must start with a letter\\n    - Cannot end with a hyphen or underscore\\n    \\\"\\\"\\\"\\n    pattern = r'^[a-zA-Z][a-zA-Z0-9-_]{0,62}[a-zA-Z0-9]$'\\n    \\n    return re.match(pattern, function_name) is not None\\n\\n# Test cases\\ntest_cases = [\\n    \\\"my-lambda-function\\\",     # Valid\\n    \\\"MyLambdaFunction123\\\",    # Valid\\n    \\\"lambda_function_name\\\",   # Valid\\n    \\\"a\\\",                      # Valid (minimum length)\\n    \\\"my-function-name-123\\\",   # Valid\\n    \\n    \\\"-invalid-name\\\",          # Invalid (starts with hyphen)\\n    \\\"invalid-name-\\\",          # Invalid (ends with hyphen)\\n    \\\"_invalid_name\\\",          # Invalid (starts with underscore)\\n    \\\"invalid_name_\\\",          # Invalid (ends with underscore)\\n    \\\"\\\",                       # Invalid (empty)\\n    \\\"a\\\" * 65                  # Invalid (too long)\\n]\\n\\n# Run tests\\nfor case in test_cases:\\n    print(f\\\"'{case}': {validate_lambda_function_name(case)}\\\")\\n```\\n\\nLet's break down the regex pattern:\\n\\n- `^` : Start of the string\\n- `[a-zA-Z]` : Must start with a letter\\n- `[a-zA-Z0-9-_]{0,62}` : Can contain 0-62 alphanumeric characters, hyphens, or underscores\\n- `[a-zA-Z0-9]` : Must end with a letter or number\\n- `$` : End of the string\\n\\nKey constraints addressed:\\n1. Length: 1-64 characters\\n2. Must start with a letter\\n3. Can contain letters, numbers, hyphens, underscores\\n4. Cannot start or end with a hyphen or underscore\\n\\nWhen you run this script, it will test various function names and show whether they are valid according to AWS Lambda naming constraints.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Design a regex to validate AWS Lambda function name constraints\"\n",
      "    },\n",
      "    \"score\": 10\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Here's a Python function to convert AWS region codes to their full region names:\\n\\n```python\\ndef convert_aws_region_code(region_code):\\n    \\\"\\\"\\\"\\n    Convert AWS region code to full region name.\\n    \\n    Args:\\n        region_code (str): AWS region code (e.g., 'us-east-1')\\n    \\n    Returns:\\n        str: Full region name or the original code if not found\\n    \\\"\\\"\\\"\\n    region_mapping = {\\n        # US Regions\\n        'us-east-1': 'US East (N. Virginia)',\\n        'us-east-2': 'US East (Ohio)', \\n        'us-west-1': 'US West (N. California)',\\n        'us-west-2': 'US West (Oregon)',\\n        \\n        # Canada Regions\\n        'ca-central-1': 'Canada (Central)',\\n        \\n        # South America Regions\\n        'sa-east-1': 'South America (S\\u00e3o Paulo)',\\n        \\n        # Europe Regions\\n        'eu-west-1': 'Europe (Ireland)', \\n        'eu-west-2': 'Europe (London)',\\n        'eu-west-3': 'Europe (Paris)', \\n        'eu-central-1': 'Europe (Frankfurt)',\\n        'eu-north-1': 'Europe (Stockholm)',\\n        \\n        # Asia Pacific Regions\\n        'ap-northeast-1': 'Asia Pacific (Tokyo)', \\n        'ap-northeast-2': 'Asia Pacific (Seoul)', \\n        'ap-northeast-3': 'Asia Pacific (Osaka)',\\n        'ap-southeast-1': 'Asia Pacific (Singapore)', \\n        'ap-southeast-2': 'Asia Pacific (Sydney)', \\n        'ap-south-1': 'Asia Pacific (Mumbai)',\\n        \\n        # Middle East Regions\\n        'me-south-1': 'Middle East (Bahrain)',\\n        \\n        # Africa Regions\\n        'af-south-1': 'Africa (Cape Town)',\\n        \\n        # China Regions\\n        'cn-north-1': 'China (Beijing)',\\n        'cn-northwest-1': 'China (Ningxia)'\\n    }\\n    \\n    # Return full region name or original code if not found\\n    return region_mapping.get(region_code, region_code)\\n\\n# Example usage\\ndef main():\\n    # Test the function with different region codes\\n    regions_to_test = [\\n        'us-east-1', \\n        'eu-west-2', \\n        'ap-southeast-1', \\n        'invalid-region'\\n    ]\\n    \\n    for region in regions_to_test:\\n        print(f\\\"Region Code: {region}\\\")\\n        print(f\\\"Full Region Name: {convert_aws_region_code(region)}\\\\n\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n```\\n\\nThis implementation offers several key features:\\n\\n1. Comprehensive Region Mapping:\\n   - Covers major AWS regions across different geographical areas\\n   - Includes US, Canada, South America, Europe, Asia Pacific, Middle East, Africa, and China regions\\n\\n2. Flexible Function Design:\\n   - If a region code is not found, it returns the original code\\n   - Simple dictionary-based lookup for quick conversions\\n\\n3. Example Usage:\\n   - Includes a `main()` function demonstrating how to use the conversion function\\n   - Provides sample region code conversions\\n\\nExample Output:\\n```\\nRegion Code: us-east-1\\nFull Region Name: US East (N. Virginia)\\n\\nRegion Code: eu-west-2\\nFull Region Name: Europe (London)\\n\\nRegion Code: ap-southeast-1\\nFull Region Name: Asia Pacific (Singapore)\\n\\nRegion Code: invalid-region\\nFull Region Name: invalid-region\\n```\\n\\nAdditional Enhancements You Could Consider:\\n1. Error handling for invalid inputs\\n2. Case-insensitive region code matching\\n3. Expanding the region mapping to include more specialized or newer regions\\n\\nPotential Use Cases:\\n- Configuration management\\n- Reporting and documentation\\n- Cloud infrastructure scripts\\n- Region-specific logic in applications\\n\\nNote: AWS regularly updates its regions, so periodically review and update the region mapping to ensure accuracy.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Create a Python function to convert AWS region code to full region name\"\n",
      "    },\n",
      "    \"score\": 10\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Here's a JSON configuration for an AWS CloudWatch log group retention policy:\\n\\n```json\\n{\\n    \\\"LogGroupName\\\": \\\"/aws/myapplication/logs\\\",\\n    \\\"RetentionInDays\\\": 30,\\n    \\\"Tags\\\": [\\n        {\\n            \\\"Key\\\": \\\"Environment\\\",\\n            \\\"Value\\\": \\\"Production\\\"\\n        },\\n        {\\n            \\\"Key\\\": \\\"Project\\\",\\n            \\\"Value\\\": \\\"MyApp\\\"\\n        }\\n    ]\\n}\\n```\\n\\nKey aspects of this configuration:\\n\\n- `LogGroupName`: Specifies the name of the CloudWatch log group\\n- `RetentionInDays`: Sets log retention to 30 days (can be 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1096, 1827, 2192, 2557, 2922, 3288, or 3653)\\n- `Tags`: Optional metadata tags for better resource management\\n\\nYou can also use this in AWS CLI or CloudFormation with appropriate modifications.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a JSON configuration for an AWS CloudWatch log group retention policy\"\n",
      "    },\n",
      "    \"score\": 10\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Here's a comprehensive solution for validating AWS access key ID format using regex:\\n\\n```python\\nimport re\\n\\ndef validate_aws_access_key_id(access_key):\\n    \\\"\\\"\\\"\\n    Validate AWS Access Key ID format\\n    \\n    AWS Access Key ID characteristics:\\n    - Starts with AKIA or ASIA\\n    - Total length of 20 characters\\n    - Followed by alphanumeric characters\\n    \\\"\\\"\\\"\\n    pattern = r'^(AKIA|ASIA)[A-Z0-9]{16}$'\\n    \\n    return bool(re.match(pattern, access_key))\\n\\n# Test cases\\ntest_keys = [\\n    'AKIAIOSFODNN7EXAMPLE',   # Valid key\\n    'ASIAJ1234567890ABCDEF',  # Valid key\\n    'AKIAI123456789012345',   # Invalid (wrong length)\\n    'XXXX1234567890ABCDEFG',  # Invalid (wrong prefix)\\n    'AKIA12345',              # Invalid (too short)\\n]\\n\\nfor key in test_keys:\\n    print(f\\\"Key: {key}, Valid: {validate_aws_access_key_id(key)}\\\")\\n```\\n\\nKey points about the regex:\\n- `^` - Start of the string\\n- `(AKIA|ASIA)` - Must start with AKIA or ASIA\\n- `[A-Z0-9]{16}` - 16 uppercase letters and numbers follow\\n- `$` - End of the string\\n\\nThis regex ensures:\\n1. Correct prefix\\n2. Correct total length\\n3. Only alphanumeric characters\\n\\nRecommended additional validation:\\n- Check for recent/active key\\n- Use AWS SDK for comprehensive validation\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Develop a regex to match and validate AWS access key ID format\"\n",
      "    },\n",
      "    \"score\": 10\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Here's a comprehensive solution to determine AWS service health status from a status page URL:\\n\\n```python\\nimport requests\\nfrom bs4 import BeautifulSoup\\nimport json\\nfrom typing import Dict, List\\n\\ndef get_aws_service_health_status(url: str) -> Dict[str, str]:\\n    \\\"\\\"\\\"\\n    Retrieve AWS service health status from the given status page URL.\\n    \\n    Args:\\n        url (str): URL of the AWS Service Health Dashboard\\n    \\n    Returns:\\n        Dict[str, str]: A dictionary of service names and their current status\\n    \\\"\\\"\\\"\\n    try:\\n        # Send a GET request to the URL\\n        response = requests.get(url, timeout=10)\\n        response.raise_for_status()  # Raise an exception for bad status codes\\n        \\n        # Parse the HTML content\\n        soup = BeautifulSoup(response.text, 'html.parser')\\n        \\n        # Dictionary to store service statuses\\n        service_statuses = {}\\n        \\n        # Example parsing (may need adjustment based on actual page structure)\\n        service_elements = soup.find_all('div', class_='service-status')\\n        \\n        for element in service_elements:\\n            service_name = element.find('span', class_='service-name').text.strip()\\n            status = element.find('span', class_='status').text.strip()\\n            service_statuses[service_name] = status\\n        \\n        return service_statuses\\n    \\n    except requests.RequestException as e:\\n        print(f\\\"Error fetching status: {e}\\\")\\n        return {}\\n\\ndef check_overall_aws_health(url: str) -> str:\\n    \\\"\\\"\\\"\\n    Determine overall AWS health status\\n    \\n    Args:\\n        url (str): URL of the AWS Service Health Dashboard\\n    \\n    Returns:\\n        str: Overall health status\\n    \\\"\\\"\\\"\\n    service_statuses = get_aws_service_health_status(url)\\n    \\n    # Count different status types\\n    status_counts = {\\n        'Operational': 0,\\n        'Performance Issues': 0,\\n        'Partial Outage': 0,\\n        'Full Outage': 0\\n    }\\n    \\n    for status in service_statuses.values():\\n        if status == 'Operational':\\n            status_counts['Operational'] += 1\\n        elif status == 'Performance Issues':\\n            status_counts['Performance Issues'] += 1\\n        elif status == 'Partial Outage':\\n            status_counts['Partial Outage'] += 1\\n        elif status == 'Full Outage':\\n            status_counts['Full Outage'] += 1\\n    \\n    # Determine overall status\\n    if status_counts['Full Outage'] > 0:\\n        return 'Critical - Full Outage Detected'\\n    elif status_counts['Partial Outage'] > 0:\\n        return 'Warning - Partial Outage'\\n    elif status_counts['Performance Issues'] > 0:\\n        return 'Caution - Performance Degradation'\\n    else:\\n        return 'Healthy - All Services Operational'\\n\\ndef monitor_aws_services(url: str, interval: int = 300) -> None:\\n    \\\"\\\"\\\"\\n    Continuously monitor AWS service health\\n    \\n    Args:\\n        url (str): URL of the AWS Service Health Dashboard\\n        interval (int): Monitoring interval in seconds (default 5 minutes)\\n    \\\"\\\"\\\"\\n    import time\\n    import logging\\n    \\n    # Configure logging\\n    logging.basicConfig(\\n        level=logging.INFO,\\n        format='%(asctime)s - AWS Service Health Monitor',\\n        filename='aws_health_log.txt'\\n    )\\n    \\n    while True:\\n        try:\\n            # Check overall health\\n            overall_status = check_overall_aws_health(url)\\n            \\n            # Log the status\\n            logging.info(f\\\"Current AWS Service Health Status: {overall_status}\\\")\\n            \\n            # Wait before next check\\n            time.sleep(interval)\\n        \\n        except Exception as e:\\n            logging.error(f\\\"Monitoring error: {e}\\\")\\n            time.sleep(interval)\\n\\ndef main():\\n    # AWS Status Page URL (replace with actual URL)\\n    AWS_STATUS\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Create a Python function to determine AWS service health status from a status page URL\"\n",
      "    },\n",
      "    \"score\": 10\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2828b6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-studies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
